---
layout: post
title:  "decision tree读书会简讯"
date:   2015-12-23 18:10:12
categories: news
---

12月23日下午3:30，学科组的崔星灿同学为学科组的同学们带来主题为“Splitting datasets one feature at a time:decision trees”的读书会，简要介绍决策树的基础知识。

在读书会上，崔星灿同学首先以一个关于源码许可证的例子向大家形象化的介绍了决策树的三要素，包括判断模块decision block，终止模块terminating block和分支branch。接下来简要说明了决策树的构建过程，并主要针对如何构建决策树分支和寻找最好特征展开说明。然后详细介绍了决策树的理论基础——熵和信息增益，包括它们的定义、计算和使用等。其中，熵指的是热力学中的香农熵，在此定义为信息的期望值，熵越高，则混合的数据越多，因此可通过计算划分数据集的信息熵来衡量数据集的划分是否正确等。之后讨论终止决策分类的条件：所有的特征都已用完或每个分支下的实例具有相同的标签。为了方便理解，给出一个关于男女分类的例子，并结合python程序进一步介绍利用决策树进行分类的过程。最后，崔星灿同学带领大家回顾了本次读书会的重点内容，包括决策树分类的优缺点、效率和过拟合等问题。

在读书会的尾声阶段，大家针对决策树的相关问题进行讨论，例如对于样本不均衡的情况，决策树方法是否适用等，进一步加强了对决策树的理解。

<a href ="{{site.url}}/files/2015-12-23-1.pptx">decison tree-崔星灿</a>
